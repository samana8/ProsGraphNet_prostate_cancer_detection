{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Image Registration Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from preprocess import *\n",
    "import SimpleITK as sitk\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from register_images_GNN import *\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from parse_registration_json import ParserRegistrationJson\n",
    "from parse_study_dict import ParserStudyDict\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Input, Set and Create Output Dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INPUTS\n",
    "json_path = \"./jsonData/TCIA_FUSION.json\"\n",
    "preprocess_moving = True\n",
    "preprocess_fixed = True\n",
    "run_registration = True\n",
    "extension = 'nii.gz'\n",
    "timings = {}\n",
    "\n",
    "try:\n",
    "    with open('coord.txt') as f:\n",
    "        coord = json.load(f)   \n",
    "        \n",
    "except:\n",
    "    coord = {}\n",
    "\n",
    "############### START REGISTRATION HERE\n",
    "\n",
    "json_obj = ParserRegistrationJson(json_path)\n",
    "\n",
    "studies = json_obj.studies\n",
    "toProcess = json_obj.ToProcess\n",
    "outputPath = json_obj.output_path\n",
    "#cases = toProcess.keys()\n",
    "\n",
    "if not os.path.isdir(outputPath):\n",
    "    os.mkdir(outputPath) \n",
    "\n",
    "###### PREPROCESSING DESTINATIONS ######################################\n",
    "preprocess_moving_dest = os.path.join(outputPath, 'preprocess', 'hist')\n",
    "preprocess_fixed_dest = os.path.join(outputPath, 'preprocess', 'mri')\n",
    "\n",
    "if not os.path.isdir(os.path.join(outputPath, 'preprocess')):\n",
    "    os.mkdir(os.path.join(outputPath, 'preprocess'))\n",
    "\n",
    "if not os.path.isdir(preprocess_moving_dest):\n",
    "    os.mkdir(preprocess_moving_dest)\n",
    "    \n",
    "if not os.path.isdir(preprocess_fixed_dest):\n",
    "    os.mkdir(preprocess_fixed_dest)\n",
    "\n",
    "# print(json_obj.studies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Image and Save Output in nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start doing preprocessing on each case and register\n",
    "for s in json_obj.studies:\n",
    "    if json_obj.ToProcess:\n",
    "        if not (s in json_obj.ToProcess):\n",
    "            print(\"Skipping\", s)\n",
    "            continue\n",
    "\n",
    "    print(\"x\"*30, \"Processing\", s,\"x\"*30)\n",
    "    studyDict = json_obj.studies[s] \n",
    "\n",
    "\n",
    "    studyParser = ParserStudyDict(studyDict)\n",
    "    \n",
    "    sid = studyParser.id\n",
    "    fixed_img_mha = studyParser.fixed_filename\n",
    "    fixed_seg = studyParser.fixed_segmentation_filename\n",
    "    moving_dict = studyParser.ReadMovingImage()\n",
    "\n",
    "    ###### PREPROCESSING HISTOLOGY HERE #############################################################\n",
    "    if preprocess_moving == True: \n",
    "        print('Preprocessing moving sid:', sid, '...')\n",
    "        print(preprocess_moving_dest)\n",
    "        preprocess_hist(moving_dict, preprocess_moving_dest, sid)\n",
    "        print('Finished preprocessing', sid)\n",
    "\n",
    "    ###### PREPROCESSING MRI HERE #############################################################\n",
    "    if preprocess_fixed == True:\n",
    "        print (\"Preprocessing fixed case:\", sid, '...')\n",
    "        print(preprocess_fixed_dest)\n",
    "        coord = preprocess_mri(fixed_img_mha, fixed_seg, preprocess_fixed_dest, coord, sid)\n",
    "\n",
    "        print(\"Finished processing fixed mha\", sid)\n",
    "\n",
    "        with open('coord.txt', 'w') as json_file: \n",
    "            json.dump(coord, json_file)\n",
    "    ##### ALIGNMENT HERE ########################################################################\n",
    "    if run_registration == True: \n",
    "        \n",
    "        ######## LOAD MODELS\n",
    "        print('.'*30, 'Begin deep learning registration for ' + sid + '.'*30)\n",
    "\n",
    "        try:\n",
    "            model_cache\n",
    "        except NameError:\n",
    "            model_aff_path = './trained_models/best_CombinedLoss_affine_GNN_LR0.00045_segments100.pth.tar'\n",
    "            model_tps_path = './trained_models/best_CombinedLoss_tps_GNN_LR0.00045_segments100.pth.tar'\n",
    "\n",
    "            model_cache = load_models(model_aff_path, model_tps_path, do_deformable=True)\n",
    "        \n",
    "        start = time.time()\n",
    "        output3D_cache = register(preprocess_moving_dest, preprocess_fixed_dest, coord, model_cache, sid)\n",
    "        out3Dhist_highRes, out3Dmri_highRes, out3Dcancer_highRes, out3D_region00, out3D_region10, out3D_region09, out3Dmri_mask = output3D_cache\n",
    "\n",
    "        # print(f\"out3Dhist_highRes: {out3Dhist_highRes.shape}, \" \\\n",
    "        #   f\"out3Dmri_highRes: {out3Dmri_highRes.shape}, \" \\\n",
    "        #   f\"out3Dcancer_highRes: {out3Dcancer_highRes.shape}, \" \\\n",
    "        #   f\"out3D_region00: {out3D_region00.shape}, \" \\\n",
    "        #   f\"out3D_region10: {out3D_region10.shape}, \" \\\n",
    "        #   f\"out3D_region09: {out3D_region09.shape}, \" \\\n",
    "        #   f\"out3Dmri_mask: {out3Dmri_mask.shape}\"\n",
    "        # )\n",
    "        end = time.time()\n",
    "        print(\"Registration done in {:6.3f}(min)\".format((end-start)/60.0))\n",
    "        imMri = sitk.ReadImage(fixed_img_mha)\n",
    "        mriOrigin = imMri[:,:,coord[sid]['slice'][0]:coord[sid]['slice'][-1]].GetOrigin()\n",
    "        mriSpace  = imMri.GetSpacing()\n",
    "        mriDirection = imMri.GetDirection()\n",
    "\n",
    "        imSpatialInfo = (mriOrigin, mriSpace, mriDirection)\n",
    "\n",
    "        # write output hist 3D volume to .nii.gz format\n",
    "        fn_moving_highRes = '_moved_highres_rgb.'\n",
    "        print('_moved_highres_rgb')\n",
    "        output_results_high_res(preprocess_moving_dest,preprocess_fixed_dest,outputPath, out3Dhist_highRes, sid, fn_moving_highRes, imSpatialInfo, coord, imMri, extension = \"nii.gz\")\n",
    "\n",
    "        #write output mri 3D volume to .nii.gz format\n",
    "        fn_fixed_highRes = '_fixed_image.'\n",
    "        print('_fixed_image')\n",
    "        output_results(outputPath, out3Dmri_highRes, sid, fn_fixed_highRes, imSpatialInfo, extension = \"nii.gz\")\n",
    "\n",
    "        #write output cancer outline 3D volume to .nii.gz format\n",
    "        fn_cancer_highRes = '_moved_highres_region01_label.'\n",
    "        print('_moved_highres_region01_label')\n",
    "        output_results_high_res(preprocess_moving_dest,preprocess_fixed_dest,outputPath, out3Dcancer_highRes, sid, fn_cancer_highRes, imSpatialInfo, coord, imMri, extension = \"nii.gz\")\n",
    "        \n",
    "        #write region00\n",
    "        fn_region00 = '_moved_highres_region00_label.'\n",
    "\n",
    "        output_results_high_res(preprocess_moving_dest,preprocess_fixed_dest,outputPath, out3D_region00, sid, fn_region00, imSpatialInfo, coord, imMri, extension = \"nii.gz\")\n",
    "        \n",
    "        #write region10\n",
    "        fn_region00 = '_moved_highres_region10_label.'\n",
    "        output_results_high_res(preprocess_moving_dest,preprocess_fixed_dest,outputPath, out3D_region10, sid, fn_region00, imSpatialInfo, coord, imMri, extension = \"nii.gz\")\n",
    "        \n",
    "        #write region09\n",
    "        fn_region00 = '_moved_highres_region09_label.'\n",
    "        output_results_high_res(preprocess_moving_dest,preprocess_fixed_dest,outputPath, out3D_region09, sid, fn_region00, imSpatialInfo, coord, imMri, extension = \"nii.gz\")\n",
    "        \n",
    "        #write mriMask\n",
    "        fn_mriMask = '_fixed_mask_label.'\n",
    "        output_results(outputPath, out3Dmri_mask, sid, fn_mriMask, imSpatialInfo, extension = \"nii.gz\")\n",
    "\n",
    "        timings[s] = (end-start)/60.0\n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(timings, open(\"timings_LR0_00045_seg_100.txt\",'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and Save output in png format from nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def nii_to_image(nii_file_path, output_dir, slice_index=None):\n",
    "    \"\"\"\n",
    "    Convert a .nii.gz file to a set of images.\n",
    "\n",
    "    Parameters:\n",
    "    - nii_file_path: Path to the .nii.gz file.\n",
    "    - output_dir: Directory where the images will be saved.\n",
    "    - slice_index: Index of the slice to be saved as an image. Default is 0.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for f in os.listdir(nii_file_path):\n",
    "        if not os.path.isdir(os.path.join(nii_file_path, f)):\n",
    "            # Read the .nii.gz file\n",
    "            sitk_image = sitk.ReadImage(os.path.join(nii_file_path, f))\n",
    "            \n",
    "            # Get the image as a NumPy array\n",
    "            image_array = sitk.GetArrayFromImage(sitk_image)\n",
    "            \n",
    "            # Ensure the output directory exists\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # Save each slice as an image\n",
    "            for i in range(image_array.shape[0]):\n",
    "                slice_img = image_array[i, :, :]\n",
    "                slice_img_normalized = cv2.normalize(slice_img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "                output_path = os.path.join(output_dir, f\"{f.split('.')[0]}_slice_{i}.png\")\n",
    "                cv2.imwrite(output_path, slice_img_normalized)\n",
    "                print(f\"Saved slice {i} as {output_path}\")\n",
    "\n",
    "            # Optionally save a specific slice\n",
    "            if slice_index is not None and isinstance(slice_index, int):\n",
    "                if 0 <= slice_index < image_array.shape[0]:\n",
    "                    specific_slice = image_array[slice_index, :, :]\n",
    "                    specific_slice_normalized = cv2.normalize(specific_slice, None, 0, 255, cv2.NORM_MINMAX)\n",
    "                    specific_output_path = os.path.join(output_dir, f\"{f.split('.')[0]}_slice_{slice_index}.png\")\n",
    "                    cv2.imwrite(specific_output_path, specific_slice_normalized)\n",
    "                    print(f\"Saved specific slice {slice_index} as {specific_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./results_LR0_00045_seg100/aaa0069/images\"\n",
    "\n",
    "nii_to_image(\"./results_LR0_00045_seg100/aaa0069\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice and View images using AVX2 feature of CPU for 7x faster slicing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Much faster than the standard class\n",
    "from fast_slic.avx2 import SlicAvx2\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir(\"/home/ubuntu/Document/ProsGraphNet/\")\n",
    "os.listdir()\n",
    "\n",
    "img_path = \"./datasets/datasets/training/mri_TCIA-0002_10.jpg\"\n",
    "\n",
    "# with Image.open() as f:\n",
    "#    image = np.array(f)\n",
    "\n",
    "num_of_seg = 60\n",
    "compactness = 30\n",
    "\n",
    "image = cv2.imread(img_path)   # You can convert the image to CIELAB space if you need.\n",
    "slic = SlicAvx2(num_components=num_of_seg, compactness=compactness)\n",
    "assignment = slic.iterate(image) # Cluster Map\n",
    "# print(assignment)\n",
    "# print(slic.slic_model.clusters) # The cluster information of superpixels.\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(assignment)\n",
    "plt.title(f\" MRI SLIC Segmentation:- {num_of_seg} segments, {compactness} compactness\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV from logged Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "names = ['Epoch', 'LR-Segments', 'Training Loss', 'Test Loss', 'Dice']\n",
    "base_path = \"./training_data/training_logs\"\n",
    "geometric_model = 'tps'\n",
    "for fname in os.listdir(base_path):\n",
    "    if geometric_model in fname:\n",
    "        print(f\"{geometric_model} Current File: {fname}\")\n",
    "        f_data = None\n",
    "        \n",
    "        if 'train' in fname:\n",
    "            with open(os.path.join(base_path, fname)) as f:\n",
    "                f_data = f.readlines()\n",
    "                \n",
    "            epoch = 1\n",
    "            for line in f_data:\n",
    "                if 'Average loss' in line:\n",
    "                    training_data.append([epoch, f\"{fname.split('_')[1].split('LR')[1]}-{fname.split('_')[4]}\", float(line.split(' ')[-1].replace('\\n', ''))])\n",
    "                    epoch += 1\n",
    "\n",
    "testing_data_x = []\n",
    "testing_data_y = []\n",
    "for fname in os.listdir(base_path):\n",
    "    if geometric_model in fname:\n",
    "        print(f\"{geometric_model} Current File: {fname}\")\n",
    "        x = []\n",
    "        y = []\n",
    "        f_data = None\n",
    "        \n",
    "        if 'test' in fname:\n",
    "            with open(os.path.join(base_path, fname)) as f:\n",
    "                f_data = f.readlines()\n",
    "                \n",
    "            epoch = 1\n",
    "            for idx, line in enumerate(f_data):\n",
    "                if 'Average loss' in line:\n",
    "                    testing_data_x.append([epoch, f\"{fname.split('_')[1].split('LR')[1]}-{fname.split('_')[4]}\", float(line.split(' ')[-1].replace('\\n', ''))])\n",
    "                    epoch += 1\n",
    "            epoch = 1\n",
    "            for idx, line in enumerate(f_data):\n",
    "                if 'Dice' in line:\n",
    "                    testing_data_y.append([epoch, f\"{fname.split('_')[1].split('LR')[1]}-{fname.split('_')[4]}\", float(line.split(' ')[-1].replace('\\n', ''))])\n",
    "                    epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_records(training_data, columns=names[:3])\n",
    "df2 = pd.DataFrame.from_records(testing_data_x, columns=[names[0], names[1], names[3]])\n",
    "df3 = pd.DataFrame.from_records(testing_data_y, columns=[names[0], names[1], names[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m1 = pd.merge(df1, df2, on=['Epoch', 'LR-Segments'], how='inner')\n",
    "df_m2 = pd.merge(df_m1, df3, on=['Epoch', 'LR-Segments'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m2.to_csv(\"./training_data/training_testing_loss_dice_tps.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay detected outputs and save as image in results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "img_dir = \"./results_LR0_00045_seg100/aaa0069/images/\"\n",
    "imgs = os.listdir(img_dir)\n",
    "\n",
    "grpd_imgs = []\n",
    "for img in imgs:\n",
    "    if int(img.split('.')[0].split('_')[-1]) == 0:\n",
    "        if len(grpd_imgs) == 0:\n",
    "            grpd_imgs.append([os.path.join(img_dir, img)])\n",
    "        else:\n",
    "            grpd_imgs[0].append(os.path.join(img_dir, img))\n",
    "    elif int(img.split('.')[0].split('_')[-1]) == 1:\n",
    "        if len(grpd_imgs) == 0:\n",
    "            grpd_imgs.append([])\n",
    "            grpd_imgs.append([os.path.join(img_dir, img)])\n",
    "        elif len(grpd_imgs) == 1:\n",
    "            grpd_imgs.append([os.path.join(img_dir, img)])\n",
    "        else:\n",
    "            grpd_imgs[1].append(os.path.join(img_dir, img))\n",
    "    else:\n",
    "        if len(grpd_imgs) == 0:\n",
    "            grpd_imgs.append([])\n",
    "            grpd_imgs.append([])\n",
    "            grpd_imgs.append([os.path.join(img_dir, img)])\n",
    "        elif len(grpd_imgs) == 1:\n",
    "            grpd_imgs.append([])\n",
    "            grpd_imgs.append([os.path.join(img_dir, img)])\n",
    "        elif len(grpd_imgs) == 2:\n",
    "            grpd_imgs.append([os.path.join(img_dir, img)])\n",
    "        else:\n",
    "            grpd_imgs[2].append(os.path.join(img_dir, img))\n",
    "\n",
    "\n",
    "# # Load the images\n",
    "for i, grp in enumerate(grpd_imgs):\n",
    "    mri_img_name = [n for n in grp if 'image_slice' in n][0]\n",
    "    mask1_name = [n for n in grp if 'mask_label_slice' in n][0]\n",
    "    mask2_name = [n for n in grp if 'region00' in n][0]\n",
    "    mask3_name = [n for n in grp if 'region01' in n][0]\n",
    "    mask4_name = [n for n in grp if 'region09' in n][0]\n",
    "    mask5_name = [n for n in grp if 'region10' in n][0]\n",
    "    \n",
    "    mri_image = cv2.imread(mri_img_name)\n",
    "    overlay_image = mri_image.copy()\n",
    "    mask1 = cv2.imread(mask1_name, cv2.IMREAD_GRAYSCALE)\n",
    "    mask2 = cv2.imread(mask2_name, cv2.IMREAD_GRAYSCALE)\n",
    "    mask3 = cv2.imread(mask3_name, cv2.IMREAD_GRAYSCALE)\n",
    "    mask4 = cv2.imread(mask4_name, cv2.IMREAD_GRAYSCALE)\n",
    "    mask5 = cv2.imread(mask5_name, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    mask2 = cv2.resize(mask2, (320,320), cv2.INTER_AREA)\n",
    "    mask3 = cv2.resize(mask3, (320,320), cv2.INTER_AREA)\n",
    "    mask4 = cv2.resize(mask4, (320,320), cv2.INTER_AREA)\n",
    "    mask5 = cv2.resize(mask5, (320,320), cv2.INTER_AREA)\n",
    "\n",
    "    contours = []\n",
    "    # Detect contours\n",
    "    contours1, _ = cv2.findContours(mask1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours2, _ = cv2.findContours(mask2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours3, _ = cv2.findContours(mask3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours4, _ = cv2.findContours(mask4, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours5, _ = cv2.findContours(mask5, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [(contours2, (255, 0, 255)), (contours3, (0, 0, 254)), (contours4, (0, 0, 255)), (contours5, (0, 0, 255))]\n",
    "\n",
    "    # Create a blank canvas to draw contours on\n",
    "    # contour_image = np.zeros_like(mask1, dtype=np.uint8)  # Create a black canvas\n",
    "\n",
    "    # draw base image label slice\n",
    "    cv2.drawContours(overlay_image, contours1, -1, (0,255, 0), 1)\n",
    "\n",
    "    for contour in contours:\n",
    "        shifted_contours = []\n",
    "        for c in contour[0]:\n",
    "            shifted_contour = c - [15, 15]\n",
    "            shifted_contours.append(shifted_contour)\n",
    "\n",
    "        # Draw the contours on the black canvas\n",
    "        cv2.drawContours(overlay_image, shifted_contours, -1, contour[1], 1)  # White contours for the first mask\n",
    "\n",
    "\n",
    "    # Display the contours in grayscale\n",
    "    # plt.figure(figsize=(6, 6))\n",
    "    # plt.imshow(contour_image, cmap='gray')\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    # Display the final image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cv2.cvtColor(overlay_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    cv2.imwrite(os.path.join(img_dir, f'aaa0069_LR0_00035_seg_80_slice_{i}.png'), overlay_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
